{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498392bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST dataset...\n",
      "Preprocessing the data...\n",
      "Code execution reached this point.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load MNIST dataset and split into training and testing sets\n",
    "print(\"Loading MNIST dataset...\")\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data - normalize pixel values between 0 and 1\n",
    "print(\"Preprocessing the data...\")\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Adding a console to reflect runtime issues\n",
    "print(\"Code execution reached this point.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c2918d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code executed successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reshape images to match CNN input shape (add channel dimension)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1)\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Adding a console to reflect successful execution\n",
    "print(\"Code executed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f256c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture with ReLU activation and L2 regularization\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1),\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b95c0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with appropriate optimizer and loss function\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4b5d992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 35s 35ms/step - loss: 0.5405 - accuracy: 0.9102 - val_loss: 0.2477 - val_accuracy: 0.9830\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.2835 - accuracy: 0.9621 - val_loss: 0.2651 - val_accuracy: 0.9631\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 33s 35ms/step - loss: 0.2351 - accuracy: 0.9666 - val_loss: 0.1663 - val_accuracy: 0.9851\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 33s 35ms/step - loss: 0.2118 - accuracy: 0.9708 - val_loss: 0.1539 - val_accuracy: 0.9869\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.2055 - accuracy: 0.9716 - val_loss: 0.2450 - val_accuracy: 0.9569\n",
      "Code executed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train the model on training set with data augmentation\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=64),\n",
    "                    epochs=5,\n",
    "                    validation_data=(x_test, y_test))\n",
    "# Adding a console to reflect successful execution\n",
    "print(\"Code executed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf212f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code executed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Function to recognize a handwritten digit from an image file\n",
    "def recognize_digit(image_path):\n",
    "    # Load and preprocess the image\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "    img = img / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # Predict the digit using the trained model\n",
    "    prediction = model.predict(img)\n",
    "    digit = np.argmax(prediction)\n",
    "    \n",
    "    return digit\n",
    "\n",
    "# Adding a console to reflect successful execution\n",
    "print(\"Code executed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "290ef7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 'q' to quit or press Enter to recognize a digit: \n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "Recognized digit from 'sample.png': 3\n",
      "Enter 'q' to quit or press Enter to recognize a digit: q\n",
      "Application terminated.\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder where user-placed images are stored\n",
    "user_images_folder = \"user_images/\"\n",
    "\n",
    "# Loop to continuously recognize digits from user images\n",
    "while True:\n",
    "    user_input = input(\"Enter 'q' to quit or press Enter to recognize a digit: \")\n",
    "    \n",
    "    if user_input.lower() == 'q':\n",
    "        break\n",
    "    \n",
    "    # List image files in the user_images_folder\n",
    "    image_files = [f for f in os.listdir(user_images_folder) if os.path.isfile(os.path.join(user_images_folder, f))]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No images found in the folder. Please place an image in the user_images folder.\")\n",
    "        continue\n",
    "    \n",
    "    # Choose the first image for recognition (you can modify this part to choose specific files)\n",
    "    image_to_recognize = image_files[0]\n",
    "    image_path = os.path.join(user_images_folder, image_to_recognize)\n",
    "    \n",
    "    # Recognize the digit from the chosen image\n",
    "    recognized_digit = recognize_digit(image_path)\n",
    "    \n",
    "    print(f\"Recognized digit from '{image_to_recognize}': {recognized_digit}\")\n",
    "\n",
    "print(\"Application terminated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "744c5e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2450 - accuracy: 0.9569\n",
      "Test Loss: 0.24497610330581665\n",
      "Test Accuracy: 0.9569000005722046\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained model on the entire test set\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddbc18c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c67187f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef9d21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068699d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f559e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eaebd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2096bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
